{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e260af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish importing packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.80M/6.80M [00:01<00:00, 5.62MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish initializing a driver\n",
      "- Finish importing the login credentials\n",
      "- Finish keying in email\n",
      "- Finish keying in password\n",
      "- Finish Task 1: Login to Linkedin\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and packages for the project \n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import csv\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from parsel import selector\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "print('- Finish importing packages')\n",
    "\n",
    "def GetUrl():\n",
    "    #urls = driver.find_element_by_class_name('entity-result__title-text t-16')\n",
    "    #urls = urls.find_elements_by_css_selector('a')\n",
    "    #linkedin_urls = [url.get_attribute('href') for url in urls]\n",
    "    src = driver.page_source\n",
    "    # Now using beautiful soup\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    links = soup.find_all('div', {'class': 'mb1'})\n",
    "    cnt_links = len(links)\n",
    "\n",
    "    linkedin_urls = []\n",
    "    for i in range(cnt_links):\n",
    "        link = links[i].find('a', {'class': 'app-aware-link'}).get(\"href\")\n",
    "        linkedin_urls.append(link)\n",
    "        \n",
    "    final_urls = []\n",
    "    for url in linkedin_urls:\n",
    "            if url == None:\n",
    "                continue\n",
    "            elif '.linkedin.com/in/' in url:\n",
    "                final_urls.append(url)\n",
    "\n",
    "    return final_urls\n",
    "\n",
    "\n",
    "def load_page():\n",
    "    start = time.time()\n",
    "\n",
    "    # will be used in the while loop\n",
    "    initialScroll = 0\n",
    "    finalScroll = 1000\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(f\"window.scrollTo({initialScroll},{finalScroll})\")\n",
    "        # this command scrolls the window starting from\n",
    "        # the pixel value stored in the initialScroll\n",
    "        # variable to the pixel value stored at the\n",
    "        # finalScroll variable\n",
    "        initialScroll = finalScroll\n",
    "        finalScroll += 1000\n",
    "\n",
    "        # we will stop the script for 3 seconds so that\n",
    "        # the data can load\n",
    "        time.sleep(2)\n",
    "        # You can change it as per your needs and internet speed\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # We will scroll for 20 seconds.\n",
    "        # You can change it as per your needs and internet speed\n",
    "        if round(end - start) > 5:\n",
    "            break\n",
    "\n",
    "\n",
    "# Task 1: Login to Linkedin\n",
    "\n",
    "# Task 1.1: Open Chrome and Access Linkedin login site\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "sleep(2)\n",
    "url = 'https://www.linkedin.com/login'\n",
    "driver.get(url)\n",
    "print('- Finish initializing a driver')\n",
    "sleep(2)\n",
    "\n",
    "# Task 1.2: Import username and password\n",
    "\n",
    "#\"C:\\Users\\Admin\\OneDrive - Viscadia Inc\\Desktop\\Rajat Workstreams\\Linkedin Web Scraping\\credentials.txt.txt\"\n",
    "# credential = open('credentials.txt')\n",
    "\n",
    "\n",
    "credential = open('credentials.txt')\n",
    "\n",
    "line = credential.readlines()\n",
    "username = line[0]\n",
    "password = line[1]\n",
    "print('- Finish importing the login credentials')\n",
    "sleep(2)\n",
    "\n",
    "# Task 1.2: Key in login credentials\n",
    "# email_field = driver.find_element_by_id('username')\n",
    "\n",
    "email_field = driver.find_element(\"id\", \"username\")\n",
    "\n",
    "email_field.send_keys(username)\n",
    "print('- Finish keying in email')\n",
    "sleep(3)\n",
    "\n",
    "# password_field = driver.find_element_by_name('session_password')\n",
    "\n",
    "password_field = driver.find_element(\"name\",\"session_password\")\n",
    "\n",
    "password_field.send_keys(password)\n",
    "print('- Finish keying in password')\n",
    "sleep(2)\n",
    "\n",
    "# Task 1.2: Click the Login button\n",
    "signin_field = driver.find_element(By.XPATH,'//*[@type=\"submit\"]')\n",
    "signin_field.click()\n",
    "sleep(3)\n",
    "\n",
    "print('- Finish Task 1: Login to Linkedin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "805530ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish Task 2: Search for profiles\n",
      "- Finish Task 3: Scrape the URLs\n",
      "-Data Scraping is in process\n"
     ]
    }
   ],
   "source": [
    "searches = open('Search_queries.txt')\n",
    "queries = searches.readlines()\n",
    "\n",
    "final_dataset = {}\n",
    "\n",
    "for search in range(len(queries)):\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    search_query = queries[search]\n",
    "    driver.get(\"https://www.linkedin.com/search/results/people/\" + search_query)\n",
    "\n",
    "    #search_query = str(input('Enter your search query: '))\n",
    "\n",
    "    \n",
    "        #print(linkedin_urls)\n",
    "\n",
    "        \n",
    "    input_page = 1\n",
    "    #int(input('How many pages you want to scrape: '))\n",
    "\n",
    "    #for i in range(1, 10):\n",
    "    #    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    #    time.sleep(2)\n",
    "\n",
    "    URLs_all_page = []\n",
    "\n",
    "    for page in range(input_page):\n",
    "        driver.get('https://www.linkedin.com/search/results/people/?keywords=' + search_query + \"&page=\" + str(page + 1))\n",
    "        time.sleep(5)\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') #scroll to the end of the page\n",
    "        time.sleep(5)\n",
    "        URLs_one_page = GetUrl()\n",
    "        URLs_all_page = URLs_all_page + URLs_one_page\n",
    "        sleep(2)\n",
    "\n",
    "    print('- Finish Task 2: Search for profiles')\n",
    "\n",
    "    for idx,url in enumerate(URLs_all_page):\n",
    "        pos = url.find('?')\n",
    "        URLs_all_page[idx] = url[:pos]\n",
    "\n",
    "\n",
    "    print('- Finish Task 3: Scrape the URLs')\n",
    "\n",
    "    print('-Data Scraping is in process')\n",
    "\n",
    "\n",
    "    Names = []\n",
    "    Intros = []\n",
    "    Locations = []\n",
    "    Companies = []\n",
    "    Colleges = []\n",
    "    Profile_links = []\n",
    "    Last_activity_links = []\n",
    "    Abouts = []\n",
    "    Connection_types = []\n",
    "    Mutuals_list = []\n",
    "    Current_positions = []\n",
    "    Experience_tenure = []\n",
    "    Institutes_list = []\n",
    "    last_certifications = []\n",
    "    last_cert_timelines = []\n",
    "    Exp_firm=[]\n",
    "    Exp_Pos=[]\n",
    "    # URLs_all_page=URLs_all_page[:2]\n",
    "    for url in URLs_all_page:\n",
    "        driver.get(url)\n",
    "        load_page()\n",
    "\n",
    "        # Extracting the HTML of the complete introduction box\n",
    "        # that contains the name, company name, and the location\n",
    "\n",
    "        src = driver.page_source\n",
    "\n",
    "        # Now using beautiful soup\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "        intro_1 = soup.find('div', {'class': 'pv-text-details__left-panel'})\n",
    "        intro_2 = soup.find('ul', {'class': 'pv-text-details__right-panel'})\n",
    "        intro_3 = soup.find('div', {'class': 'pv-text-details__left-panel mt2'})\n",
    "\n",
    "        #Extracting name\n",
    "\n",
    "        try:\n",
    "            name_loc = intro_1.find(\"h1\")\n",
    "            name = name_loc.get_text().strip()\n",
    "        except:\n",
    "            name = \"\"\n",
    "\n",
    "        #Extracting bio\n",
    "\n",
    "        try:\n",
    "            works_at_loc = intro_1.find(\"div\", {'class': 'text-body-medium'})\n",
    "            works_at = works_at_loc.get_text().strip()\n",
    "        except:\n",
    "            works_at = \"\"\n",
    "\n",
    "        #Extracting location\n",
    "\n",
    "        try:\n",
    "            location_loc = intro_3.find_all(\"span\", {'class': 'text-body-small'})\n",
    "            location = location_loc[0]\n",
    "            location = location.get_text().strip()\n",
    "        except:\n",
    "            location = \"\"\n",
    "\n",
    "        #Extracting About section\n",
    "\n",
    "        try:\n",
    "            About_section = soup.find('div', {'class': 'display-flex ph5 pv3'})\n",
    "            About = About_section.find(\"span\", {'class': 'visually-hidden'})\n",
    "            About = About.get_text()\n",
    "        except:\n",
    "            About = \"\"\n",
    "\n",
    "        #Extracting recent activity link\n",
    "\n",
    "        pos = url.rfind('/')\n",
    "        username = url[(pos+1):]\n",
    "\n",
    "        try:\n",
    "            recent_activity = 'https://www.linkedin.com/in/' + username + '/recent-activity/'\n",
    "        except:\n",
    "            recent_activity = \"\"\n",
    "\n",
    "        #Extracting current status\n",
    "\n",
    "        try:\n",
    "            current_status = intro_2.find_all('div', {'class': 'inline-show-more-text'})\n",
    "            Current_company = current_status[0].get_text().strip()\n",
    "            Last_education = current_status[1].get_text().strip()\n",
    "        except:\n",
    "            Current_company = \"\"\n",
    "            Last_education = \"\"\n",
    "\n",
    "        #Extracting connection type\n",
    "\n",
    "        try:\n",
    "            connection = intro_1.find(\"span\")\n",
    "            connection = connection.find('span', {'class': 'visually-hidden'})\n",
    "            connection = connection.get_text().strip()\n",
    "        except:\n",
    "            connection = \"\"\n",
    "\n",
    "        #Extracting mutual connections\n",
    "\n",
    "        try:\n",
    "            mutuals = soup.find('span', {'class': 't-normal t-black--light t-14 hoverable-link-text'})\n",
    "            mutuals = mutuals.find_all('strong')\n",
    "            mutual_connections = []\n",
    "            mutuals_cnt = int(len(mutuals)/2)\n",
    "\n",
    "            for i in range(mutuals_cnt):\n",
    "                mutual_connections.append(mutuals[i].get_text().strip())\n",
    "\n",
    "        except:\n",
    "            mutual_connections = []\n",
    "\n",
    "\n",
    "        #Extracting Current Position and tenure\n",
    "\n",
    "        try:\n",
    "            pos = url.rfind('/')\n",
    "            username = url[(pos+1):]\n",
    "            experience_url = 'https://www.linkedin.com/in/' + username + '/details/experience/'\n",
    "            driver.get(experience_url)\n",
    "            load_page()\n",
    "\n",
    "            src = driver.page_source\n",
    "\n",
    "            soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "            current_position = soup.find_all('span', {'class': 'mr1 hoverable-link-text t-bold'})\n",
    "\n",
    "            current_position = current_position[0].find_all('span')\n",
    "            current_position = current_position[0].get_text().strip()\n",
    "\n",
    "            if current_position == Current_company:\n",
    "\n",
    "                current_position = soup.find_all('span', {'class': 'mr1 hoverable-link-text t-bold'})\n",
    "                current_position = current_position[1].find_all('span')\n",
    "                current_position = current_position[0].get_text().strip()\n",
    "\n",
    "                tenure = soup.find_all('span', {'class': 't-14 t-normal'})\n",
    "                tenure = tenure[0].find_all('span')\n",
    "                tenure = tenure[0].get_text()\n",
    "\n",
    "            else:\n",
    "\n",
    "                current_position = soup.find_all('span', {'class': 'mr1 t-bold'})\n",
    "                current_position = current_position[0].find_all('span')\n",
    "                current_position = current_position[0].get_text()\n",
    "\n",
    "                tenure = soup.find_all('span', {'class': 't-14 t-normal t-black--light'})\n",
    "                tenure = tenure[0].find_all('span')\n",
    "                tenure = tenure[0].get_text()\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                current_position = soup.find_all('span', {'class': 'mr1 t-bold'})\n",
    "                current_position = current_position[0].find_all('span')\n",
    "                current_position = current_position[0].get_text()\n",
    "            except:\n",
    "                current_position = \"\"\n",
    "\n",
    "            try:    \n",
    "                tenure = soup.find_all('span', {'class': 't-14 t-normal t-black--light'})\n",
    "                tenure = tenure[0].find_all('span')\n",
    "                tenure = tenure[0].get_text()\n",
    "            except:\n",
    "                tenure = \"\"\n",
    "\n",
    "        #Extracting experience companies and posttions        \n",
    "        Exp_Companies =[]\n",
    "        Exp_Roles =[]\n",
    "        firm=[]\n",
    "        roles=[]    \n",
    "        try:\n",
    "            \n",
    "            pos = url.rfind('/')\n",
    "            username = url[(pos+1):]\n",
    "            experience_url = 'https://www.linkedin.com/in/' + username + '/details/experience/'\n",
    "            driver.get(experience_url)\n",
    "            load_page()\n",
    "\n",
    "            src = driver.page_source\n",
    "\n",
    "            soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "            Exp_Companies=soup.find_all('div',{'class' : 'pvs-entity pvs-entity--padded pvs-list__item--no-padding-in-columns'})\n",
    "            for expc in range(len(Exp_Companies)):\n",
    "                ec=Exp_Companies[expc].find('span', {'class': 'mr1 t-bold'})\n",
    "                if(ec==None):\n",
    "                    Exp_Roles=Exp_Companies[expc].find_all('span', {'class': 'mr1 hoverable-link-text t-bold'})\n",
    "                    firm.append(Exp_Roles[0].find('span').get_text())\n",
    "                    Exp_Roles=Exp_Roles[1:]\n",
    "                    roles.append(list(map(lambda x: x.find('span').get_text(),Exp_Roles)))\n",
    "                else:\n",
    "                    roles.append(ec.find('span').get_text()) \n",
    "                    ec=Exp_Companies[expc].find('span',{'class':'t-14 t-normal'}) \n",
    "                    firm.append(ec.find('span').get_text())\n",
    "        except:\n",
    "           firm=\"\"\n",
    "           roles=\"\"\n",
    "        \n",
    "        #Extracting Education details\n",
    "\n",
    "        \n",
    "        try:\n",
    "            pos = url.rfind('/')\n",
    "            username = url[(pos+1):]\n",
    "            experience_url = 'https://www.linkedin.com/in/' + username + '/details/education/'\n",
    "            driver.get(experience_url)\n",
    "            load_page()\n",
    "\n",
    "            src = driver.page_source\n",
    "\n",
    "            soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "            Institute = soup.find_all('span', {'class': 'mr1 hoverable-link-text t-bold'})\n",
    "\n",
    "            Institute_cnt = len(Institute)\n",
    "\n",
    "            Institute_list = []\n",
    "\n",
    "            for i in range(Institute_cnt):\n",
    "                cur_inst = Institute[i].find('span')\n",
    "                cur_inst = cur_inst.get_text().strip()\n",
    "                Institute_list.append(cur_inst)\n",
    "\n",
    "        except:\n",
    "            Institute_list = []\n",
    "\n",
    "        #Extracting last education degree\n",
    "\n",
    "        try:\n",
    "            last_certification = soup.find_all('span', {'class': 't-14 t-normal'})\n",
    "            last_certification = last_certification[0].find_all('span')\n",
    "            last_certification = last_certification[0].get_text()\n",
    "\n",
    "        except:\n",
    "            last_certification = \"\"\n",
    "\n",
    "        #Extracting last degree timeline\n",
    "\n",
    "        try:\n",
    "            last_cert_timeline = soup.find_all('span', {'class': 't-14 t-normal t-black--light'})\n",
    "            last_cert_timeline = last_cert_timeline[0].find_all('span')\n",
    "            last_cert_timeline = last_cert_timeline[0].get_text()\n",
    "\n",
    "        except:\n",
    "            last_cert_timeline = \"\" \n",
    "\n",
    "\n",
    "        Names.append(name)\n",
    "        Intros.append(works_at)\n",
    "        Locations.append(location)\n",
    "        Abouts.append(About)\n",
    "        Profile_links.append(url)\n",
    "        Last_activity_links.append(recent_activity)\n",
    "        Companies.append(Current_company)\n",
    "        Colleges.append(Last_education)\n",
    "        Connection_types.append(connection)\n",
    "        Mutuals_list.append(mutual_connections)\n",
    "        Current_positions.append(current_position)\n",
    "        Experience_tenure.append(tenure)\n",
    "        Institutes_list.append(Institute_list)\n",
    "        last_certifications.append(last_certification)\n",
    "        last_cert_timelines.append(last_cert_timeline)\n",
    "        Exp_firm.append(firm)\n",
    "        Exp_Pos.append(roles)\n",
    "\n",
    "        final_data = [Names,Exp_firm ,Exp_Pos , Intros, Connection_types, Locations, Abouts, Companies, Current_positions, \n",
    "                      Experience_tenure, Mutuals_list, Colleges, last_certifications, last_cert_timelines, \n",
    "                      Institutes_list, Profile_links, Last_activity_links]\n",
    "\n",
    "        col_names = ['Name','ExpFirm','ExpRoles' ,'Introduction', 'Connection Type', 'Location', 'About', 'Current Company', 'Current Position', 'Tenure at Current Organization',\n",
    "                    'Mutual Connections', 'Most Recent Institute', 'Most Recent Degree', 'Degree Timeline', 'Almae Matres', 'Profile Link', 'See Activities']\n",
    "\n",
    "        df = pd.DataFrame(final_data, index = col_names)\n",
    "        df = df.T\n",
    "        final_dataset[search_query] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "759fd88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.linkedin.com/in/lavishgupta',\n",
       " 'https://www.linkedin.com/in/poojasharma2895']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLs_all_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bba2f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Lavish Gupta', 'Pooja Sharma'], [['Viscadia · Full-time', 'OYO', 'ZS · Full-time', 'SS Supply Chain Solution (3SC)', 'Cognizance, IIT Roorkee', 'Log 9 Materials', 'Larsen & Toubro', 'Cognizance, IIT Roorkee', 'Cognizance, IIT Roorkee'], ['Viscadia · Full-time', 'Simon Vision Consulting · Seasonal', 'ZS · Full-time', 'Vodafone', 'Bharat Sanchar Nigam Limited · Internship']], [['Associate Consultant', ['Project Manager - Global Revenue', 'Project Manager - Supply Excellence'], 'Decision Analytics Associate', 'Solution Development Intern', 'Manager (Exhibitions & Techtainment)', 'Product Marketing Consultant', 'Internship at \"The Crest, DLF 5, Gurgaon\"', 'Coordinator (Exhibitions & Techtainment)', 'Co-Coordinator (Exhibitions & Techtainment)'], ['Associate Consultant', 'Business Consultant', 'Decision Analytics Associate', ['Assistant Manager', 'Senior Executive'], 'Intern']], ['Strategy Consultant | Commercial Analytics | Go-to-Market Strategies | Problem Solving | Project Management', 'Associate Consultant, Strategic Forecasting at Viscadia'], ['2nd degree connection', ''], ['Gurugram, Haryana, India', 'Cambridge, Massachusetts, United States'], [\"I am a strategy consultant with 5+ years of industry experience in complex problem-solving and creating go-to-market strategies.\\n\\nSome examples include - \\n\\nI am working as an Associate Consultant at Viscadia in creating pipeline and on-market product forecasting solutions.\\nI worked with OYO, India's largest and the world's fastest-growing hotel chain as a Project Manager where I created go-to-market solutions to increase profitability at the overall network level. \\nI worked with ZS Associates, a global management consulting firm, where I helped multiple Fortune 500 pharmaceutical companies in improving their sales force effectiveness.\\n\\nI get excited about opportunities where I get to create solutions using data-driven meaningful insights.\", 'Experience: Management Consulting - Life sciences '], ['Viscadia', 'Viscadia'], ['Associate Consultant', 'Associate Consultant'], ['Nov 2020 - Present · 2 yrs 6 mos', 'Jun 2022 - Present · 11 mos'], [['Shruti Gupta', 'Herav Jassal'], ['Harshit Rana', 'Shruti Gupta']], ['Indian Institute of Technology, Roorkee', 'University of Rochester - Simon Business School'], ['Bachelor’s Degree, Civil Engineering', 'Master of Science - MS, Business Analytics'], ['2013 - 2017', '2021 - 2022'], [['Indian Institute of Technology, Roorkee', 'Saraswati Vidya Mandir Senior Secondary School', 'R.R.K. Senior Secondary School'], ['University of Rochester - Simon Business School', 'Vellore Institute of Technology', \"Maharani Gayatri Devi Girls'\\u200b School\"]], ['https://www.linkedin.com/in/lavishgupta', 'https://www.linkedin.com/in/poojasharma2895'], ['https://www.linkedin.com/in/lavishgupta/recent-activity/', 'https://www.linkedin.com/in/poojasharma2895/recent-activity/']]\n"
     ]
    }
   ],
   "source": [
    "print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dfd31c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccc76174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          Lavish Gupta\n",
       "1     [Viscadia · Full-time, OYO, ZS · Full-time, SS...\n",
       "2     [Associate Consultant, [Project Manager - Glob...\n",
       "3     Strategy Consultant | Commercial Analytics | G...\n",
       "4                                 2nd degree connection\n",
       "5                              Gurugram, Haryana, India\n",
       "6     I am a strategy consultant with 5+ years of in...\n",
       "7                                              Viscadia\n",
       "8                                  Associate Consultant\n",
       "9                      Nov 2020 - Present · 2 yrs 6 mos\n",
       "10                         [Shruti Gupta, Herav Jassal]\n",
       "11              Indian Institute of Technology, Roorkee\n",
       "12                 Bachelor’s Degree, Civil Engineering\n",
       "13                                          2013 - 2017\n",
       "14    [Indian Institute of Technology, Roorkee, Sara...\n",
       "15              https://www.linkedin.com/in/lavishgupta\n",
       "16    https://www.linkedin.com/in/lavishgupta/recent...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2903fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "\n",
    "df = pd.DataFrame(final_data)\n",
    "\n",
    "# write the dataframe to an Excel file\n",
    "writer = pd.ExcelWriter('output.xlsx', engine='openpyxl')\n",
    "df.to_excel(writer, index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba9ec037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lavish Gupta</td>\n",
       "      <td>[Viscadia · Full-time, OYO, ZS · Full-time, SS...</td>\n",
       "      <td>[Associate Consultant, [Project Manager - Glob...</td>\n",
       "      <td>Strategy Consultant | Commercial Analytics | G...</td>\n",
       "      <td>2nd degree connection</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>I am a strategy consultant with 5+ years of in...</td>\n",
       "      <td>Viscadia</td>\n",
       "      <td>Associate Consultant</td>\n",
       "      <td>Nov 2020 - Present · 2 yrs 6 mos</td>\n",
       "      <td>[Shruti Gupta, Herav Jassal]</td>\n",
       "      <td>Indian Institute of Technology, Roorkee</td>\n",
       "      <td>Bachelor’s Degree, Civil Engineering</td>\n",
       "      <td>2013 - 2017</td>\n",
       "      <td>[Indian Institute of Technology, Roorkee, Sara...</td>\n",
       "      <td>https://www.linkedin.com/in/lavishgupta</td>\n",
       "      <td>https://www.linkedin.com/in/lavishgupta/recent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pooja Sharma</td>\n",
       "      <td>[Viscadia · Full-time, Simon Vision Consulting...</td>\n",
       "      <td>[Associate Consultant, Business Consultant, De...</td>\n",
       "      <td>Associate Consultant, Strategic Forecasting at...</td>\n",
       "      <td></td>\n",
       "      <td>Cambridge, Massachusetts, United States</td>\n",
       "      <td>Experience: Management Consulting - Life scien...</td>\n",
       "      <td>Viscadia</td>\n",
       "      <td>Associate Consultant</td>\n",
       "      <td>Jun 2022 - Present · 11 mos</td>\n",
       "      <td>[Harshit Rana, Shruti Gupta]</td>\n",
       "      <td>University of Rochester - Simon Business School</td>\n",
       "      <td>Master of Science - MS, Business Analytics</td>\n",
       "      <td>2021 - 2022</td>\n",
       "      <td>[University of Rochester - Simon Business Scho...</td>\n",
       "      <td>https://www.linkedin.com/in/poojasharma2895</td>\n",
       "      <td>https://www.linkedin.com/in/poojasharma2895/re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                                                  1   \\\n",
       "0  Lavish Gupta  [Viscadia · Full-time, OYO, ZS · Full-time, SS...   \n",
       "1  Pooja Sharma  [Viscadia · Full-time, Simon Vision Consulting...   \n",
       "\n",
       "                                                  2   \\\n",
       "0  [Associate Consultant, [Project Manager - Glob...   \n",
       "1  [Associate Consultant, Business Consultant, De...   \n",
       "\n",
       "                                                  3                      4   \\\n",
       "0  Strategy Consultant | Commercial Analytics | G...  2nd degree connection   \n",
       "1  Associate Consultant, Strategic Forecasting at...                          \n",
       "\n",
       "                                        5   \\\n",
       "0                 Gurugram, Haryana, India   \n",
       "1  Cambridge, Massachusetts, United States   \n",
       "\n",
       "                                                  6         7   \\\n",
       "0  I am a strategy consultant with 5+ years of in...  Viscadia   \n",
       "1  Experience: Management Consulting - Life scien...  Viscadia   \n",
       "\n",
       "                     8                                 9   \\\n",
       "0  Associate Consultant  Nov 2020 - Present · 2 yrs 6 mos   \n",
       "1  Associate Consultant       Jun 2022 - Present · 11 mos   \n",
       "\n",
       "                             10  \\\n",
       "0  [Shruti Gupta, Herav Jassal]   \n",
       "1  [Harshit Rana, Shruti Gupta]   \n",
       "\n",
       "                                                11  \\\n",
       "0          Indian Institute of Technology, Roorkee   \n",
       "1  University of Rochester - Simon Business School   \n",
       "\n",
       "                                           12           13  \\\n",
       "0        Bachelor’s Degree, Civil Engineering  2013 - 2017   \n",
       "1  Master of Science - MS, Business Analytics  2021 - 2022   \n",
       "\n",
       "                                                  14  \\\n",
       "0  [Indian Institute of Technology, Roorkee, Sara...   \n",
       "1  [University of Rochester - Simon Business Scho...   \n",
       "\n",
       "                                            15  \\\n",
       "0      https://www.linkedin.com/in/lavishgupta   \n",
       "1  https://www.linkedin.com/in/poojasharma2895   \n",
       "\n",
       "                                                  16  \n",
       "0  https://www.linkedin.com/in/lavishgupta/recent...  \n",
       "1  https://www.linkedin.com/in/poojasharma2895/re...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32242d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ccfc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff2653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6712a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "181ef940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_button = driver.find_element(\"name\",\"artdeco-button__text\")\n",
    "# driver.execute_script(\"arguments[0].click();\", next_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6992b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e15c48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs_all_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68f14675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_field = driver.find_element_by_class_name('ember-view')\n",
    "\n",
    "# # Task 2.2: Input the search query to the search bar\n",
    "# search_query = input('What profile do you want to scrape? ')\n",
    "# search_field.send_keys(search_query)\n",
    "\n",
    "# # Task 2.3: Search\n",
    "# search_field.send_keys(Keys.RETURN)\n",
    "# # Task 2: Search for the profile we want to crawl\n",
    "\n",
    "# # Task 2.1: Locate the search bar element\n",
    "# driver.get('https://www.google.com')\n",
    "# time.sleep(2)\n",
    "\n",
    "# # locate search form by_name\n",
    "# search_query = driver.find_element_by_name('q')\n",
    "\n",
    "# # Task 2.2: Input the search query to the search bar\n",
    "# search = input('What profile do you want to scrape? ')\n",
    "\n",
    "# # send_keys() to simulate the search text key strokes\n",
    "# search_query.send_keys('site:linkedin.com/in/ AND ' + search)\n",
    "\n",
    "# # .send_keys() to simulate the return key \n",
    "# search_query.send_keys(Keys.RETURN)\n",
    "\n",
    "# print('- Finish Task 2: Search for profiles')\n",
    "\n",
    "# def GetUrl():\n",
    "#     urls = driver.find_elements_by_css_selector('a')\n",
    "#     linkedin_urls = [url.get_attribute('href') for url in urls]\n",
    "\n",
    "#     final_urls = []\n",
    "#     for url in linkedin_urls:\n",
    "#             if url == None:\n",
    "#                 continue\n",
    "#             elif '.linkedin.com/in/' in url:\n",
    "#                 final_urls.append(url)\n",
    "        \n",
    "#     return final_urls\n",
    "\n",
    "# input_page = int(input('How many pages you want to scrape: '))\n",
    "# URLs_all_page = []\n",
    "# for page in range(input_page):\n",
    "#     URLs_one_page = GetUrl()\n",
    "#     sleep(2)\n",
    "#     next_button = driver.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]')\n",
    "#     driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "#     URLs_all_page = URLs_all_page + URLs_one_page\n",
    "#     sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb6be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4857e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
